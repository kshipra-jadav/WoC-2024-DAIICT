{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Using Support Vector Machine For Review Classification",
   "id": "8e8df624fbc84a06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:29:08.931424Z",
     "start_time": "2025-01-19T16:29:08.091883Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "72642a8964543bee",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:29:17.864784Z",
     "start_time": "2025-01-19T16:29:13.810627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_json('../checkpoint-1/processed_data.json', orient='records', lines=True)\n",
    "\n",
    "df.head()"
   ],
   "id": "aa605f4ae125a5b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           category  rating label  \\\n",
       "0  Home and Kitchen       5    CG   \n",
       "1  Home and Kitchen       5    CG   \n",
       "2  Home and Kitchen       5    CG   \n",
       "3  Home and Kitchen       1    CG   \n",
       "4  Home and Kitchen       5    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...   \n",
       "1  love it, a great upgrade from the original.  I...   \n",
       "2  This pillow saved my back. I love the look and...   \n",
       "3  Missing information on how to use it, but it i...   \n",
       "4  Very nice set. Good quality. We have had the s...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  love well made sturdy comfortable love itvery ...   \n",
       "1  love great upgrade original ive mine couple years   \n",
       "2            pillow saved back love look feel pillow   \n",
       "3        missing information use great product price   \n",
       "4               nice set good quality set two months   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  [love, well, made, sturdy, comfortable, love, ...   \n",
       "1  [love, great, upgrade, original, ive, mine, co...   \n",
       "2    [pillow, saved, back, love, look, feel, pillow]   \n",
       "3  [missing, information, use, great, product, pr...   \n",
       "4       [nice, set, good, quality, set, two, months]   \n",
       "\n",
       "                                     text_embeddings  \n",
       "0  [-0.06552676860000001, 0.0019102807000000001, ...  \n",
       "1  [-0.11993740500000001, 0.0896221548, 0.0629631...  \n",
       "2  [-0.0531752855, 0.0186075028, 0.0380044468, 0....  \n",
       "3  [0.007157366300000001, 0.0636947528, 0.0084662...  \n",
       "4  [-0.0369832478, 0.011753053400000001, 0.041596...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "      <td>[love, well, made, sturdy, comfortable, love, ...</td>\n",
       "      <td>[-0.06552676860000001, 0.0019102807000000001, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>love great upgrade original ive mine couple years</td>\n",
       "      <td>[love, great, upgrade, original, ive, mine, co...</td>\n",
       "      <td>[-0.11993740500000001, 0.0896221548, 0.0629631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "      <td>[pillow, saved, back, love, look, feel, pillow]</td>\n",
       "      <td>[-0.0531752855, 0.0186075028, 0.0380044468, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>missing information use great product price</td>\n",
       "      <td>[missing, information, use, great, product, pr...</td>\n",
       "      <td>[0.007157366300000001, 0.0636947528, 0.0084662...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>nice set good quality set two months</td>\n",
       "      <td>[nice, set, good, quality, set, two, months]</td>\n",
       "      <td>[-0.0369832478, 0.011753053400000001, 0.041596...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:29:20.503060Z",
     "start_time": "2025-01-19T16:29:20.422771Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.dropna()",
   "id": "a573e75bb1b18377",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:29:20.806500Z",
     "start_time": "2025-01-19T16:29:20.786949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df['text_embeddings'].tolist()\n",
    "y = df['label'].tolist()\n",
    "\n",
    "len(X), len(y)"
   ],
   "id": "725ab806405f1be4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40408, 40408)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:29:23.612901Z",
     "start_time": "2025-01-19T16:29:21.274718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "y_encoded = lb.fit_transform(y).reshape(-1) # flattening the array"
   ],
   "id": "ffb5438134d80a6b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:29:23.773059Z",
     "start_time": "2025-01-19T16:29:23.616931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, train_size=0.8)"
   ],
   "id": "d15a73eae98d453f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:29:23.784989Z",
     "start_time": "2025-01-19T16:29:23.775082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Num Samples in Training Set - {len(X_train)}, {len(y_train)}\")\n",
    "print(f\"Num Samples in Testing Set  - {len(X_test)}, {len(y_test)}\")"
   ],
   "id": "5a190f17f3d99744",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples in Training Set - 32326, 32326\n",
      "Num Samples in Testing Set  - 8082, 8082\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:29:26.594545Z",
     "start_time": "2025-01-19T16:29:23.784989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmscaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = mmscaler.fit_transform(X_train)\n",
    "X_test_scaled = mmscaler.transform(X_test)"
   ],
   "id": "f9700da5535df29a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Getting A Baseline Score",
   "id": "8fb86d5c86987c63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:41:27.596723Z",
     "start_time": "2025-01-19T16:33:31.070413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_preds_base = svc.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Baseline Score of SVM - {classification_report(y_test, y_preds_base)}\")"
   ],
   "id": "61e12bac80585d54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Score of SVM -               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60      3988\n",
      "           1       0.62      0.66      0.64      4094\n",
      "\n",
      "    accuracy                           0.62      8082\n",
      "   macro avg       0.62      0.62      0.62      8082\n",
      "weighted avg       0.62      0.62      0.62      8082\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exporting The Model",
   "id": "f539145631613976"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:45:02.520895Z",
     "start_time": "2025-01-19T16:45:02.406708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svc, \"support-vector-machine.joblib\")"
   ],
   "id": "a0916a3b26ebd476",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['support-vector-machine.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
